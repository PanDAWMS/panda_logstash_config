filter {
	if ([type]=="brokerlog")
	{
		mutate {
			rename => {"message"=>"garbage"}
		}
		ruby {
		code => "
			event['garbage']  = event['garbage'].split.join(' ')"
		}
		if ("hospital queues" in [garbage])
		{
			grok {
				patterns_dir => "/opt/logstash/patterns/"
				match => { "garbage" => "%{TIMESTAMP_ISO8601:timeEvent} %{TYPE:logName}: %{WORD:logLevel} %{GREEDYDATA:message}" }	
			}
			mutate {
				remove_field => ['garbage','tags']
			}
			mutate {
				add_tag => ['hospital_queues']
			}
		}
		else
		{
			grok {
				patterns_dir => "/opt/logstash/patterns/"
				match => { "garbage" => "%{TIMESTAMP_ISO8601:timeEvent} %{TYPE:logName}: %{WORD:logLevel} %{NOTSPACE:timeid} %{GREEDYDATA:message}" }	
			}

			mutate {
				remove_field => ['garbage']
			}
			aggregate {
				task_id => "%{timeid}"
				code => "
					map['tags'] ||= ['aggregated']
					map['message'] ||= []
					event.to_hash.each do |key,value|
						map[key] = value unless map.has_key?(key)
						map[key] << value if map[key].is_a?(Array)
					end
				"
				push_previous_map_as_event => true
				timeout => 5
				remove_tag => ["beats_input_codec_plain_applied"]
			}
			if "aggregated" not in [tags] 
			{
				drop {}
			}
			mutate {
				remove_field => ["tags"]
			}
			mutate {
				add_tag => ['not_hospital_queues']
			}
			ruby {
				code => "
					fieldArray = event['message']
					if (fieldArray.index('new bunch')!=nil)
						startIndex = fieldArray.index('new bunch')+1
						endIndex = fieldArray.each_index.select{|i| fieldArray[i] =~ %r'DDM' or fieldArray[i] =~ %r'cache/relSites'}.last
						splitField = fieldArray[startIndex..endIndex]
						for field in splitField
							key = field.rpartition(' ').first 
							value = field.rpartition(' ').last
							event [key] = value
						end
					concatMas = fieldArray[0..startIndex-2]+fieldArray[endIndex+1..fieldArray.length-1]
					event ['message']=concatMas 
					else
					event ['message']=fieldArray 
					end
				"
			}
		}
	}
}